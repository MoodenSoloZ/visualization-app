{"ast":null,"code":"import _slicedToArray from \"/Users/weihangzhang/Documents/webpage/gosling-react/node_modules/@babel/runtime/helpers/esm/slicedToArray.js\";\nimport _toConsumableArray from \"/Users/weihangzhang/Documents/webpage/gosling-react/node_modules/@babel/runtime/helpers/esm/toConsumableArray.js\";\nimport _createForOfIteratorHelper from \"/Users/weihangzhang/Documents/webpage/gosling-react/node_modules/@babel/runtime/helpers/esm/createForOfIteratorHelper.js\";\nimport _classCallCheck from \"/Users/weihangzhang/Documents/webpage/gosling-react/node_modules/@babel/runtime/helpers/esm/classCallCheck.js\";\nimport _createClass from \"/Users/weihangzhang/Documents/webpage/gosling-react/node_modules/@babel/runtime/helpers/esm/createClass.js\";\nimport _inherits from \"/Users/weihangzhang/Documents/webpage/gosling-react/node_modules/@babel/runtime/helpers/esm/inherits.js\";\nimport _createSuper from \"/Users/weihangzhang/Documents/webpage/gosling-react/node_modules/@babel/runtime/helpers/esm/createSuper.js\";\nimport { fieldIntersection, hash, hasIntersection, isEmpty, keys, some } from '../../util';\nimport { requiresSelectionId } from '../selection';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { OutputNode } from './dataflow';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { ParseNode } from './formatparse';\nimport { IdentifierNode } from './identifier';\nimport { BottomUpOptimizer, isDataSourceNode, Optimizer, TopDownOptimizer } from './optimizer';\nimport { SourceNode } from './source';\nimport { TimeUnitNode } from './timeunit';\n/**\n * Merge identical nodes at forks by comparing hashes.\n *\n * Does not need to iterate from leaves so we implement this with recursion as it's a bit simpler.\n */\nexport var MergeIdenticalNodes = /*#__PURE__*/function (_TopDownOptimizer) {\n  _inherits(MergeIdenticalNodes, _TopDownOptimizer);\n  var _super = _createSuper(MergeIdenticalNodes);\n  function MergeIdenticalNodes() {\n    _classCallCheck(this, MergeIdenticalNodes);\n    return _super.apply(this, arguments);\n  }\n  _createClass(MergeIdenticalNodes, [{\n    key: \"mergeNodes\",\n    value: function mergeNodes(parent, nodes) {\n      var mergedNode = nodes.shift();\n      var _iterator = _createForOfIteratorHelper(nodes),\n        _step;\n      try {\n        for (_iterator.s(); !(_step = _iterator.n()).done;) {\n          var node = _step.value;\n          parent.removeChild(node);\n          node.parent = mergedNode;\n          node.remove();\n        }\n      } catch (err) {\n        _iterator.e(err);\n      } finally {\n        _iterator.f();\n      }\n    }\n  }, {\n    key: \"run\",\n    value: function run(node) {\n      var hashes = node.children.map(function (x) {\n        return x.hash();\n      });\n      var buckets = {};\n      for (var i = 0; i < hashes.length; i++) {\n        if (buckets[hashes[i]] === undefined) {\n          buckets[hashes[i]] = [node.children[i]];\n        } else {\n          buckets[hashes[i]].push(node.children[i]);\n        }\n      }\n      var _iterator2 = _createForOfIteratorHelper(keys(buckets)),\n        _step2;\n      try {\n        for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n          var k = _step2.value;\n          if (buckets[k].length > 1) {\n            this.setModified();\n            this.mergeNodes(node, buckets[k]);\n          }\n        }\n      } catch (err) {\n        _iterator2.e(err);\n      } finally {\n        _iterator2.f();\n      }\n    }\n  }]);\n  return MergeIdenticalNodes;\n}(TopDownOptimizer);\n/**\n * Optimizer that removes identifier nodes that are not needed for selections.\n */\nexport var RemoveUnnecessaryIdentifierNodes = /*#__PURE__*/function (_TopDownOptimizer2) {\n  _inherits(RemoveUnnecessaryIdentifierNodes, _TopDownOptimizer2);\n  var _super2 = _createSuper(RemoveUnnecessaryIdentifierNodes);\n  function RemoveUnnecessaryIdentifierNodes(model) {\n    var _this;\n    _classCallCheck(this, RemoveUnnecessaryIdentifierNodes);\n    _this = _super2.call(this);\n    _this.requiresSelectionId = model && requiresSelectionId(model);\n    return _this;\n  }\n  _createClass(RemoveUnnecessaryIdentifierNodes, [{\n    key: \"run\",\n    value: function run(node) {\n      if (node instanceof IdentifierNode) {\n        // Only preserve IdentifierNodes if we have default discrete selections\n        // in our model tree, and if the nodes come after tuple producing nodes.\n        if (!(this.requiresSelectionId && (isDataSourceNode(node.parent) || node.parent instanceof AggregateNode || node.parent instanceof ParseNode))) {\n          this.setModified();\n          node.remove();\n        }\n      }\n    }\n  }]);\n  return RemoveUnnecessaryIdentifierNodes;\n}(TopDownOptimizer);\n/**\n * Removes duplicate time unit nodes (as determined by the name of the output field) that may be generated due to\n * selections projected over time units. Only keeps the first time unit in any branch.\n *\n * This optimizer is a custom top down optimizer that keep track of produced fields in a branch.\n */\nexport var RemoveDuplicateTimeUnits = /*#__PURE__*/function (_Optimizer) {\n  _inherits(RemoveDuplicateTimeUnits, _Optimizer);\n  var _super3 = _createSuper(RemoveDuplicateTimeUnits);\n  function RemoveDuplicateTimeUnits() {\n    _classCallCheck(this, RemoveDuplicateTimeUnits);\n    return _super3.apply(this, arguments);\n  }\n  _createClass(RemoveDuplicateTimeUnits, [{\n    key: \"optimize\",\n    value: function optimize(node) {\n      this.run(node, new Set());\n      return this.modifiedFlag;\n    }\n  }, {\n    key: \"run\",\n    value: function run(node, timeUnitFields) {\n      var producedFields = new Set();\n      if (node instanceof TimeUnitNode) {\n        producedFields = node.producedFields();\n        if (hasIntersection(producedFields, timeUnitFields)) {\n          this.setModified();\n          node.removeFormulas(timeUnitFields);\n          if (node.producedFields.length === 0) {\n            node.remove();\n          }\n        }\n      }\n      var _iterator3 = _createForOfIteratorHelper(node.children),\n        _step3;\n      try {\n        for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n          var child = _step3.value;\n          this.run(child, new Set([].concat(_toConsumableArray(timeUnitFields), _toConsumableArray(producedFields))));\n        }\n      } catch (err) {\n        _iterator3.e(err);\n      } finally {\n        _iterator3.f();\n      }\n    }\n  }]);\n  return RemoveDuplicateTimeUnits;\n}(Optimizer);\n/**\n * Remove output nodes that are not required.\n */\nexport var RemoveUnnecessaryOutputNodes = /*#__PURE__*/function (_TopDownOptimizer3) {\n  _inherits(RemoveUnnecessaryOutputNodes, _TopDownOptimizer3);\n  var _super4 = _createSuper(RemoveUnnecessaryOutputNodes);\n  function RemoveUnnecessaryOutputNodes() {\n    _classCallCheck(this, RemoveUnnecessaryOutputNodes);\n    return _super4.call(this);\n  }\n  _createClass(RemoveUnnecessaryOutputNodes, [{\n    key: \"run\",\n    value: function run(node) {\n      if (node instanceof OutputNode && !node.isRequired()) {\n        this.setModified();\n        node.remove();\n      }\n    }\n  }]);\n  return RemoveUnnecessaryOutputNodes;\n}(TopDownOptimizer);\n/**\n * Move parse nodes up to forks and merges them if possible.\n */\nexport var MoveParseUp = /*#__PURE__*/function (_BottomUpOptimizer) {\n  _inherits(MoveParseUp, _BottomUpOptimizer);\n  var _super5 = _createSuper(MoveParseUp);\n  function MoveParseUp() {\n    _classCallCheck(this, MoveParseUp);\n    return _super5.apply(this, arguments);\n  }\n  _createClass(MoveParseUp, [{\n    key: \"run\",\n    value: function run(node) {\n      if (isDataSourceNode(node)) {\n        return;\n      }\n      if (node.numChildren() > 1) {\n        // Don't move parse further up but continue with parent.\n        return;\n      }\n      var _iterator4 = _createForOfIteratorHelper(node.children),\n        _step4;\n      try {\n        for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n          var child = _step4.value;\n          if (child instanceof ParseNode) {\n            if (node instanceof ParseNode) {\n              this.setModified();\n              node.merge(child);\n            } else {\n              // Don't swap with nodes that produce something that the parse node depends on (e.g. lookup).\n              if (fieldIntersection(node.producedFields(), child.dependentFields())) {\n                continue;\n              }\n              this.setModified();\n              child.swapWithParent();\n            }\n          }\n        }\n      } catch (err) {\n        _iterator4.e(err);\n      } finally {\n        _iterator4.f();\n      }\n      return;\n    }\n  }]);\n  return MoveParseUp;\n}(BottomUpOptimizer);\n/**\n * Inserts an intermediate ParseNode containing all non-conflicting parse fields and removes the empty ParseNodes.\n *\n * We assume that dependent paths that do not have a parse node can be just merged.\n */\nexport var MergeParse = /*#__PURE__*/function (_BottomUpOptimizer2) {\n  _inherits(MergeParse, _BottomUpOptimizer2);\n  var _super6 = _createSuper(MergeParse);\n  function MergeParse() {\n    _classCallCheck(this, MergeParse);\n    return _super6.apply(this, arguments);\n  }\n  _createClass(MergeParse, [{\n    key: \"run\",\n    value: function run(node) {\n      var originalChildren = _toConsumableArray(node.children);\n      var parseChildren = node.children.filter(function (child) {\n        return child instanceof ParseNode;\n      });\n      if (node.numChildren() > 1 && parseChildren.length >= 1) {\n        var commonParse = {};\n        var conflictingParse = new Set();\n        var _iterator5 = _createForOfIteratorHelper(parseChildren),\n          _step5;\n        try {\n          for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n            var parseNode = _step5.value;\n            var parse = parseNode.parse;\n            var _iterator9 = _createForOfIteratorHelper(keys(parse)),\n              _step9;\n            try {\n              for (_iterator9.s(); !(_step9 = _iterator9.n()).done;) {\n                var k = _step9.value;\n                if (!(k in commonParse)) {\n                  commonParse[k] = parse[k];\n                } else if (commonParse[k] !== parse[k]) {\n                  conflictingParse.add(k);\n                }\n              }\n            } catch (err) {\n              _iterator9.e(err);\n            } finally {\n              _iterator9.f();\n            }\n          }\n        } catch (err) {\n          _iterator5.e(err);\n        } finally {\n          _iterator5.f();\n        }\n        var _iterator6 = _createForOfIteratorHelper(conflictingParse),\n          _step6;\n        try {\n          for (_iterator6.s(); !(_step6 = _iterator6.n()).done;) {\n            var field = _step6.value;\n            delete commonParse[field];\n          }\n        } catch (err) {\n          _iterator6.e(err);\n        } finally {\n          _iterator6.f();\n        }\n        if (!isEmpty(commonParse)) {\n          this.setModified();\n          var mergedParseNode = new ParseNode(node, commonParse);\n          var _iterator7 = _createForOfIteratorHelper(originalChildren),\n            _step7;\n          try {\n            for (_iterator7.s(); !(_step7 = _iterator7.n()).done;) {\n              var childNode = _step7.value;\n              if (childNode instanceof ParseNode) {\n                var _iterator8 = _createForOfIteratorHelper(keys(commonParse)),\n                  _step8;\n                try {\n                  for (_iterator8.s(); !(_step8 = _iterator8.n()).done;) {\n                    var key = _step8.value;\n                    delete childNode.parse[key];\n                  }\n                } catch (err) {\n                  _iterator8.e(err);\n                } finally {\n                  _iterator8.f();\n                }\n              }\n              node.removeChild(childNode);\n              childNode.parent = mergedParseNode;\n              // remove empty parse nodes\n              if (childNode instanceof ParseNode && keys(childNode.parse).length === 0) {\n                childNode.remove();\n              }\n            }\n          } catch (err) {\n            _iterator7.e(err);\n          } finally {\n            _iterator7.f();\n          }\n        }\n      }\n    }\n  }]);\n  return MergeParse;\n}(BottomUpOptimizer);\n/**\n * Repeatedly remove leaf nodes that are not output or facet nodes.\n * The reason is that we don't need subtrees that don't have any output nodes.\n * Facet nodes are needed for the row or column domains.\n */\nexport var RemoveUnusedSubtrees = /*#__PURE__*/function (_BottomUpOptimizer3) {\n  _inherits(RemoveUnusedSubtrees, _BottomUpOptimizer3);\n  var _super7 = _createSuper(RemoveUnusedSubtrees);\n  function RemoveUnusedSubtrees() {\n    _classCallCheck(this, RemoveUnusedSubtrees);\n    return _super7.apply(this, arguments);\n  }\n  _createClass(RemoveUnusedSubtrees, [{\n    key: \"run\",\n    value: function run(node) {\n      if (node instanceof OutputNode || node.numChildren() > 0 || node instanceof FacetNode) {\n        // no need to continue with parent because it is output node or will have children (there was a fork)\n      } else if (node instanceof SourceNode) {\n        // ignore empty unused sources as they will be removed in optimizationDataflowHelper\n      } else {\n        this.setModified();\n        node.remove();\n      }\n    }\n  }]);\n  return RemoveUnusedSubtrees;\n}(BottomUpOptimizer);\n/**\n * Merge adjacent time unit nodes.\n */\nexport var MergeTimeUnits = /*#__PURE__*/function (_BottomUpOptimizer4) {\n  _inherits(MergeTimeUnits, _BottomUpOptimizer4);\n  var _super8 = _createSuper(MergeTimeUnits);\n  function MergeTimeUnits() {\n    _classCallCheck(this, MergeTimeUnits);\n    return _super8.apply(this, arguments);\n  }\n  _createClass(MergeTimeUnits, [{\n    key: \"run\",\n    value: function run(node) {\n      var timeUnitChildren = node.children.filter(function (x) {\n        return x instanceof TimeUnitNode;\n      });\n      var combination = timeUnitChildren.pop();\n      var _iterator10 = _createForOfIteratorHelper(timeUnitChildren),\n        _step10;\n      try {\n        for (_iterator10.s(); !(_step10 = _iterator10.n()).done;) {\n          var timeUnit = _step10.value;\n          this.setModified();\n          combination.merge(timeUnit);\n        }\n      } catch (err) {\n        _iterator10.e(err);\n      } finally {\n        _iterator10.f();\n      }\n    }\n  }]);\n  return MergeTimeUnits;\n}(BottomUpOptimizer);\nexport var MergeAggregates = /*#__PURE__*/function (_BottomUpOptimizer5) {\n  _inherits(MergeAggregates, _BottomUpOptimizer5);\n  var _super9 = _createSuper(MergeAggregates);\n  function MergeAggregates() {\n    _classCallCheck(this, MergeAggregates);\n    return _super9.apply(this, arguments);\n  }\n  _createClass(MergeAggregates, [{\n    key: \"run\",\n    value: function run(node) {\n      var aggChildren = node.children.filter(function (child) {\n        return child instanceof AggregateNode;\n      });\n      // Object which we'll use to map the fields which an aggregate is grouped by to\n      // the set of aggregates with that grouping. This is useful as only aggregates\n      // with the same group by can be merged\n      var groupedAggregates = {};\n      // Build groupedAggregates\n      var _iterator11 = _createForOfIteratorHelper(aggChildren),\n        _step11;\n      try {\n        for (_iterator11.s(); !(_step11 = _iterator11.n()).done;) {\n          var agg = _step11.value;\n          var groupBys = hash(agg.groupBy);\n          if (!(groupBys in groupedAggregates)) {\n            groupedAggregates[groupBys] = [];\n          }\n          groupedAggregates[groupBys].push(agg);\n        }\n        // Merge aggregateNodes with same key in groupedAggregates\n      } catch (err) {\n        _iterator11.e(err);\n      } finally {\n        _iterator11.f();\n      }\n      var _iterator12 = _createForOfIteratorHelper(keys(groupedAggregates)),\n        _step12;\n      try {\n        for (_iterator12.s(); !(_step12 = _iterator12.n()).done;) {\n          var group = _step12.value;\n          var mergeableAggs = groupedAggregates[group];\n          if (mergeableAggs.length > 1) {\n            var mergedAggs = mergeableAggs.pop();\n            var _iterator13 = _createForOfIteratorHelper(mergeableAggs),\n              _step13;\n            try {\n              for (_iterator13.s(); !(_step13 = _iterator13.n()).done;) {\n                var _agg = _step13.value;\n                if (mergedAggs.merge(_agg)) {\n                  node.removeChild(_agg);\n                  _agg.parent = mergedAggs;\n                  _agg.remove();\n                  this.setModified();\n                }\n              }\n            } catch (err) {\n              _iterator13.e(err);\n            } finally {\n              _iterator13.f();\n            }\n          }\n        }\n      } catch (err) {\n        _iterator12.e(err);\n      } finally {\n        _iterator12.f();\n      }\n    }\n  }]);\n  return MergeAggregates;\n}(BottomUpOptimizer);\n/**\n * Merge bin nodes and move them up through forks. Stop at filters, parse, identifier as we want them to stay before the bin node.\n */\nexport var MergeBins = /*#__PURE__*/function (_BottomUpOptimizer6) {\n  _inherits(MergeBins, _BottomUpOptimizer6);\n  var _super10 = _createSuper(MergeBins);\n  function MergeBins(model) {\n    var _this2;\n    _classCallCheck(this, MergeBins);\n    _this2 = _super10.call(this);\n    _this2.model = model;\n    return _this2;\n  }\n  _createClass(MergeBins, [{\n    key: \"run\",\n    value: function run(node) {\n      var moveBinsUp = !(isDataSourceNode(node) || node instanceof FilterNode || node instanceof ParseNode || node instanceof IdentifierNode);\n      var promotableBins = [];\n      var remainingBins = [];\n      var _iterator14 = _createForOfIteratorHelper(node.children),\n        _step14;\n      try {\n        for (_iterator14.s(); !(_step14 = _iterator14.n()).done;) {\n          var child = _step14.value;\n          if (child instanceof BinNode) {\n            if (moveBinsUp && !fieldIntersection(node.producedFields(), child.dependentFields())) {\n              promotableBins.push(child);\n            } else {\n              remainingBins.push(child);\n            }\n          }\n        }\n      } catch (err) {\n        _iterator14.e(err);\n      } finally {\n        _iterator14.f();\n      }\n      if (promotableBins.length > 0) {\n        var promotedBin = promotableBins.pop();\n        var _iterator15 = _createForOfIteratorHelper(promotableBins),\n          _step15;\n        try {\n          for (_iterator15.s(); !(_step15 = _iterator15.n()).done;) {\n            var bin = _step15.value;\n            promotedBin.merge(bin, this.model.renameSignal.bind(this.model));\n          }\n        } catch (err) {\n          _iterator15.e(err);\n        } finally {\n          _iterator15.f();\n        }\n        this.setModified();\n        if (node instanceof BinNode) {\n          node.merge(promotedBin, this.model.renameSignal.bind(this.model));\n        } else {\n          promotedBin.swapWithParent();\n        }\n      }\n      if (remainingBins.length > 1) {\n        var remainingBin = remainingBins.pop();\n        var _iterator16 = _createForOfIteratorHelper(remainingBins),\n          _step16;\n        try {\n          for (_iterator16.s(); !(_step16 = _iterator16.n()).done;) {\n            var _bin = _step16.value;\n            remainingBin.merge(_bin, this.model.renameSignal.bind(this.model));\n          }\n        } catch (err) {\n          _iterator16.e(err);\n        } finally {\n          _iterator16.f();\n        }\n        this.setModified();\n      }\n    }\n  }]);\n  return MergeBins;\n}(BottomUpOptimizer);\n/**\n * This optimizer takes output nodes that are at a fork and moves them before the fork.\n *\n * The algorithm iterates over the children and tries to find the last output node in a chain of output nodes.\n * It then moves all output nodes before that main output node. All other children (and the children of the output nodes)\n * are inserted after the main output node.\n */\nexport var MergeOutputs = /*#__PURE__*/function (_BottomUpOptimizer7) {\n  _inherits(MergeOutputs, _BottomUpOptimizer7);\n  var _super11 = _createSuper(MergeOutputs);\n  function MergeOutputs() {\n    _classCallCheck(this, MergeOutputs);\n    return _super11.apply(this, arguments);\n  }\n  _createClass(MergeOutputs, [{\n    key: \"run\",\n    value: function run(node) {\n      var children = _toConsumableArray(node.children);\n      var hasOutputChild = some(children, function (child) {\n        return child instanceof OutputNode;\n      });\n      if (!hasOutputChild || node.numChildren() <= 1) {\n        return;\n      }\n      var otherChildren = [];\n      // The output node we will connect all other nodes to.\n      // Output nodes will be added before the new node, other nodes after.\n      var mainOutput;\n      var _iterator17 = _createForOfIteratorHelper(children),\n        _step17;\n      try {\n        for (_iterator17.s(); !(_step17 = _iterator17.n()).done;) {\n          var _child = _step17.value;\n          if (_child instanceof OutputNode) {\n            var lastOutput = _child;\n            while (lastOutput.numChildren() === 1) {\n              var _lastOutput$children = _slicedToArray(lastOutput.children, 1),\n                theChild = _lastOutput$children[0];\n              if (theChild instanceof OutputNode) {\n                lastOutput = theChild;\n              } else {\n                break;\n              }\n            }\n            otherChildren.push.apply(otherChildren, _toConsumableArray(lastOutput.children));\n            if (mainOutput) {\n              // Move the output nodes before the mainOutput. We do this by setting\n              // the parent of the first not to the parent of the main output and\n              // the main output's parent to the last output.\n              // note: the child is the first output\n              node.removeChild(_child);\n              _child.parent = mainOutput.parent;\n              mainOutput.parent.removeChild(mainOutput);\n              mainOutput.parent = lastOutput;\n              this.setModified();\n            } else {\n              mainOutput = lastOutput;\n            }\n          } else {\n            otherChildren.push(_child);\n          }\n        }\n      } catch (err) {\n        _iterator17.e(err);\n      } finally {\n        _iterator17.f();\n      }\n      if (otherChildren.length) {\n        this.setModified();\n        var _iterator18 = _createForOfIteratorHelper(otherChildren),\n          _step18;\n        try {\n          for (_iterator18.s(); !(_step18 = _iterator18.n()).done;) {\n            var child = _step18.value;\n            child.parent.removeChild(child);\n            child.parent = mainOutput;\n          }\n        } catch (err) {\n          _iterator18.e(err);\n        } finally {\n          _iterator18.f();\n        }\n      }\n    }\n  }]);\n  return MergeOutputs;\n}(BottomUpOptimizer);","map":{"version":3,"sources":["../../../../src/compile/data/optimizers.ts"],"names":[],"mappings":";;;;;;;AACA,SAAc,iBAAiB,EAAE,IAAI,EAAE,eAAe,EAAE,OAAO,EAAE,IAAI,EAAE,IAAI,QAAO,YAAY;AAE9F,SAAQ,mBAAmB,QAAO,cAAc;AAChD,SAAQ,aAAa,QAAO,aAAa;AACzC,SAAQ,OAAO,QAAO,OAAO;AAC7B,SAAsB,UAAU,QAAO,YAAY;AACnD,SAAQ,SAAS,QAAO,SAAS;AACjC,SAAQ,UAAU,QAAO,UAAU;AACnC,SAAQ,SAAS,QAAO,eAAe;AACvC,SAAQ,cAAc,QAAO,cAAc;AAC3C,SAAQ,iBAAiB,EAAE,gBAAgB,EAAE,SAAS,EAAE,gBAAgB,QAAO,aAAa;AAC5F,SAAQ,UAAU,QAAO,UAAU;AACnC,SAAQ,YAAY,QAAO,YAAY;AAEvC;;;;AAIG;AACH,WAAa,mBAAoB;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OACxB,oBAAW,MAAoB,EAAE,KAAqB,EAAA;MAC3D,IAAM,UAAU,GAAG,KAAK,CAAC,KAAK,EAAE;MAAC,2CACd,KAAK;QAAA;MAAA;QAAxB,oDAA0B;UAAA,IAAf,IAAI;UACb,MAAM,CAAC,WAAW,CAAC,IAAI,CAAC;UACxB,IAAI,CAAC,MAAM,GAAG,UAAU;UACxB,IAAI,CAAC,MAAM,EAAE;;MACd;QAAA;MAAA;QAAA;MAAA;IACH;EAAC;IAAA;IAAA,OAEM,aAAI,IAAkB,EAAA;MAC3B,IAAM,MAAM,GAAG,IAAI,CAAC,QAAQ,CAAC,GAAG,CAAC,UAAA,CAAC;QAAA,OAAI,CAAC,CAAC,IAAI,EAAE;MAAA,EAAC;MAC/C,IAAM,OAAO,GAA4B,CAAA,CAAE;MAE3C,KAAK,IAAI,CAAC,GAAG,CAAC,EAAE,CAAC,GAAG,MAAM,CAAC,MAAM,EAAE,CAAC,EAAE,EAAE;QACtC,IAAI,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,KAAK,SAAS,EAAE;UACpC,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,GAAG,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC;SACxC,MAAM;UACL,OAAO,CAAC,MAAM,CAAC,CAAC,CAAC,CAAC,CAAC,IAAI,CAAC,IAAI,CAAC,QAAQ,CAAC,CAAC,CAAC,CAAC;QAC1C;;MACF,4CAEe,IAAI,CAAC,OAAO,CAAC;QAAA;MAAA;QAA7B,uDAA+B;UAAA,IAApB,CAAC;UACV,IAAI,OAAO,CAAC,CAAC,CAAC,CAAC,MAAM,GAAG,CAAC,EAAE;YACzB,IAAI,CAAC,WAAW,EAAE;YAClB,IAAI,CAAC,UAAU,CAAC,IAAI,EAAE,OAAO,CAAC,CAAC,CAAC,CAAC;UAClC;;MACF;QAAA;MAAA;QAAA;MAAA;IACH;EAAC;EAAA;AAAA,EA5BsC,gBAAgB;AA+BzD;;AAEG;AACH,WAAa,gCAAiC;EAAA;EAAA;EAG5C,0CAAY,KAAY,EAAA;IAAA;IAAA;IACtB;IACA,MAAK,mBAAmB,GAAG,KAAK,IAAI,mBAAmB,CAAC,KAAK,CAAC;IAAC;EACjE;EAAC;IAAA;IAAA,OAEM,aAAI,IAAkB,EAAA;MAC3B,IAAI,IAAI,YAAY,cAAc,EAAE;QAClC;QACA;QACA,IACE,EACE,IAAI,CAAC,mBAAmB,KACvB,gBAAgB,CAAC,IAAI,CAAC,MAAM,CAAC,IAAI,IAAI,CAAC,MAAM,YAAY,aAAa,IAAI,IAAI,CAAC,MAAM,YAAY,SAAS,CAAC,CAC5G,EACD;UACA,IAAI,CAAC,WAAW,EAAE;UAClB,IAAI,CAAC,MAAM,EAAE;QACd;MACF;IACH;EAAC;EAAA;AAAA,EAtBmD,gBAAgB;AAyBtE;;;;;AAKG;AACH,WAAa,wBAAyB;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OAC7B,kBAAS,IAAkB,EAAA;MAChC,IAAI,CAAC,GAAG,CAAC,IAAI,EAAE,IAAI,GAAG,EAAE,CAAC;MAEzB,OAAO,IAAI,CAAC,YAAY;IAC1B;EAAC;IAAA;IAAA,OAEM,aAAI,IAAkB,EAAE,cAA2B,EAAA;MACxD,IAAI,cAAc,GAAG,IAAI,GAAG,EAAU;MAEtC,IAAI,IAAI,YAAY,YAAY,EAAE;QAChC,cAAc,GAAG,IAAI,CAAC,cAAc,EAAE;QACtC,IAAI,eAAe,CAAC,cAAc,EAAE,cAAc,CAAC,EAAE;UACnD,IAAI,CAAC,WAAW,EAAE;UAClB,IAAI,CAAC,cAAc,CAAC,cAAc,CAAC;UACnC,IAAI,IAAI,CAAC,cAAc,CAAC,MAAM,KAAK,CAAC,EAAE;YACpC,IAAI,CAAC,MAAM,EAAE;UACd;QACF;;MACF,4CAEmB,IAAI,CAAC,QAAQ;QAAA;MAAA;QAAjC,uDAAmC;UAAA,IAAxB,KAAK;UACd,IAAI,CAAC,GAAG,CAAC,KAAK,EAAE,IAAI,GAAG,8BAAK,cAAc,sBAAK,cAAc,GAAE,CAAC;;MACjE;QAAA;MAAA;QAAA;MAAA;IACH;EAAC;EAAA;AAAA,EAxB2C,SAAS;AA2BvD;;AAEG;AACH,WAAa,4BAA6B;EAAA;EAAA;EACxC,wCAAA;IAAA;IAAA;EAEA;EAAC;IAAA;IAAA,OAEM,aAAI,IAAkB,EAAA;MAC3B,IAAI,IAAI,YAAY,UAAU,IAAI,CAAC,IAAI,CAAC,UAAU,EAAE,EAAE;QACpD,IAAI,CAAC,WAAW,EAAE;QAClB,IAAI,CAAC,MAAM,EAAE;MACd;IACH;EAAC;EAAA;AAAA,EAV+C,gBAAgB;AAalE;;AAEG;AACH,WAAa,WAAY;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OAChB,aAAI,IAAkB,EAAA;MAC3B,IAAI,gBAAgB,CAAC,IAAI,CAAC,EAAE;QAC1B;MACD;MAED,IAAI,IAAI,CAAC,WAAW,EAAE,GAAG,CAAC,EAAE;QAC1B;QACA;;MACD,4CAEmB,IAAI,CAAC,QAAQ;QAAA;MAAA;QAAjC,uDAAmC;UAAA,IAAxB,KAAK;UACd,IAAI,KAAK,YAAY,SAAS,EAAE;YAC9B,IAAI,IAAI,YAAY,SAAS,EAAE;cAC7B,IAAI,CAAC,WAAW,EAAE;cAClB,IAAI,CAAC,KAAK,CAAC,KAAK,CAAC;aAClB,MAAM;cACL;cACA,IAAI,iBAAiB,CAAC,IAAI,CAAC,cAAc,EAAE,EAAE,KAAK,CAAC,eAAe,EAAE,CAAC,EAAE;gBACrE;cACD;cACD,IAAI,CAAC,WAAW,EAAE;cAClB,KAAK,CAAC,cAAc,EAAE;YACvB;UACF;;MACF;QAAA;MAAA;QAAA;MAAA;MAED;IACF;EAAC;EAAA;AAAA,EA5B8B,iBAAiB;AA+BlD;;;;AAIG;AACH,WAAa,UAAW;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OACf,aAAI,IAAkB,EAAA;MAC3B,IAAM,gBAAgB,sBAAO,IAAI,CAAC,QAAQ,CAAC;MAC3C,IAAM,aAAa,GAAG,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,UAAC,KAAK;QAAA,OAAyB,KAAK,YAAY,SAAS;MAAA,EAAC;MAErG,IAAI,IAAI,CAAC,WAAW,EAAE,GAAG,CAAC,IAAI,aAAa,CAAC,MAAM,IAAI,CAAC,EAAE;QACvD,IAAM,WAAW,GAAU,CAAA,CAAE;QAC7B,IAAM,gBAAgB,GAAG,IAAI,GAAG,EAAU;QAAC,4CACnB,aAAa;UAAA;QAAA;UAArC,uDAAuC;YAAA,IAA5B,SAAS;YAClB,IAAM,KAAK,GAAG,SAAS,CAAC,KAAK;YAAC,4CACd,IAAI,CAAC,KAAK,CAAC;cAAA;YAAA;cAA3B,uDAA6B;gBAAA,IAAlB,CAAC;gBACV,IAAI,EAAE,CAAC,IAAI,WAAW,CAAC,EAAE;kBACvB,WAAW,CAAC,CAAC,CAAC,GAAG,KAAK,CAAC,CAAC,CAAC;iBAC1B,MAAM,IAAI,WAAW,CAAC,CAAC,CAAC,KAAK,KAAK,CAAC,CAAC,CAAC,EAAE;kBACtC,gBAAgB,CAAC,GAAG,CAAC,CAAC,CAAC;gBACxB;;YACF;cAAA;YAAA;cAAA;YAAA;;QACF;UAAA;QAAA;UAAA;QAAA;QAAA,4CAEmB,gBAAgB;UAAA;QAAA;UAApC,uDAAsC;YAAA,IAA3B,KAAK;YACd,OAAO,WAAW,CAAC,KAAK,CAAC;;QAC1B;UAAA;QAAA;UAAA;QAAA;QAED,IAAI,CAAC,OAAO,CAAC,WAAW,CAAC,EAAE;UACzB,IAAI,CAAC,WAAW,EAAE;UAClB,IAAM,eAAe,GAAG,IAAI,SAAS,CAAC,IAAI,EAAE,WAAW,CAAC;UAAC,4CACjC,gBAAgB;YAAA;UAAA;YAAxC,uDAA0C;cAAA,IAA/B,SAAS;cAClB,IAAI,SAAS,YAAY,SAAS,EAAE;gBAAA,4CAChB,IAAI,CAAC,WAAW,CAAC;kBAAA;gBAAA;kBAAnC,uDAAqC;oBAAA,IAA1B,GAAG;oBACZ,OAAO,SAAS,CAAC,KAAK,CAAC,GAAG,CAAC;;gBAC5B;kBAAA;gBAAA;kBAAA;gBAAA;cACF;cAED,IAAI,CAAC,WAAW,CAAC,SAAS,CAAC;cAC3B,SAAS,CAAC,MAAM,GAAG,eAAe;cAElC;cACA,IAAI,SAAS,YAAY,SAAS,IAAI,IAAI,CAAC,SAAS,CAAC,KAAK,CAAC,CAAC,MAAM,KAAK,CAAC,EAAE;gBACxE,SAAS,CAAC,MAAM,EAAE;cACnB;;UACF;YAAA;UAAA;YAAA;UAAA;QACF;MACF;IACH;EAAC;EAAA;AAAA,EA3C6B,iBAAiB;AA8CjD;;;;AAIG;AACH,WAAa,oBAAqB;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OACzB,aAAI,IAAkB,EAAA;MAC3B,IAAI,IAAI,YAAY,UAAU,IAAI,IAAI,CAAC,WAAW,EAAE,GAAG,CAAC,IAAI,IAAI,YAAY,SAAS,EAAE;QACrF;OACD,MAAM,IAAI,IAAI,YAAY,UAAU,EAAE;QACrC;OACD,MAAM;QACL,IAAI,CAAC,WAAW,EAAE;QAClB,IAAI,CAAC,MAAM,EAAE;MACd;IACH;EAAC;EAAA;AAAA,EAVuC,iBAAiB;AAa3D;;AAEG;AACH,WAAa,cAAe;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OACnB,aAAI,IAAkB,EAAA;MAC3B,IAAM,gBAAgB,GAAG,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,UAAC,CAAC;QAAA,OAAwB,CAAC,YAAY,YAAY;MAAA,EAAC;MAClG,IAAM,WAAW,GAAG,gBAAgB,CAAC,GAAG,EAAE;MAAC,6CACpB,gBAAgB;QAAA;MAAA;QAAvC,0DAAyC;UAAA,IAA9B,QAAQ;UACjB,IAAI,CAAC,WAAW,EAAE;UAClB,WAAW,CAAC,KAAK,CAAC,QAAQ,CAAC;;MAC5B;QAAA;MAAA;QAAA;MAAA;IACH;EAAC;EAAA;AAAA,EARiC,iBAAiB;AAWrD,WAAa,eAAgB;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OACpB,aAAI,IAAkB,EAAA;MAC3B,IAAM,WAAW,GAAG,IAAI,CAAC,QAAQ,CAAC,MAAM,CAAC,UAAC,KAAK;QAAA,OAA6B,KAAK,YAAY,aAAa;MAAA,EAAC;MAE3G;MACA;MACA;MACA,IAAM,iBAAiB,GAA0B,CAAA,CAAE;MAEnD;MAAA,6CACkB,WAAW;QAAA;MAAA;QAA7B,0DAA+B;UAAA,IAApB,GAAG;UACZ,IAAM,QAAQ,GAAG,IAAI,CAAC,GAAG,CAAC,OAAO,CAAC;UAClC,IAAI,EAAE,QAAQ,IAAI,iBAAiB,CAAC,EAAE;YACpC,iBAAiB,CAAC,QAAQ,CAAC,GAAG,EAAE;UACjC;UACD,iBAAiB,CAAC,QAAQ,CAAC,CAAC,IAAI,CAAC,GAAG,CAAC;QACtC;QAED;MAAA;QAAA;MAAA;QAAA;MAAA;MAAA,6CACoB,IAAI,CAAC,iBAAiB,CAAC;QAAA;MAAA;QAA3C,0DAA6C;UAAA,IAAlC,KAAK;UACd,IAAM,aAAa,GAAG,iBAAiB,CAAC,KAAK,CAAC;UAC9C,IAAI,aAAa,CAAC,MAAM,GAAG,CAAC,EAAE;YAC5B,IAAM,UAAU,GAAG,aAAa,CAAC,GAAG,EAAE;YAAC,6CACrB,aAAa;cAAA;YAAA;cAA/B,0DAAiC;gBAAA,IAAtB,IAAG;gBACZ,IAAI,UAAU,CAAC,KAAK,CAAC,IAAG,CAAC,EAAE;kBACzB,IAAI,CAAC,WAAW,CAAC,IAAG,CAAC;kBACrB,IAAG,CAAC,MAAM,GAAG,UAAU;kBACvB,IAAG,CAAC,MAAM,EAAE;kBAEZ,IAAI,CAAC,WAAW,EAAE;gBACnB;;YACF;cAAA;YAAA;cAAA;YAAA;UACF;;MACF;QAAA;MAAA;QAAA;MAAA;IACH;EAAC;EAAA;AAAA,EAlCkC,iBAAiB;AAqCtD;;AAEG;AACH,WAAa,SAAU;EAAA;EAAA;EACrB,mBAAoB,KAAY,EAAA;IAAA;IAAA;IAC9B;IADkB,OAAA,KAAK,GAAL,KAAK;IAAO;EAEhC;EAAC;IAAA;IAAA,OAEM,aAAI,IAAkB,EAAA;MAC3B,IAAM,UAAU,GAAG,EACjB,gBAAgB,CAAC,IAAI,CAAC,IACtB,IAAI,YAAY,UAAU,IAC1B,IAAI,YAAY,SAAS,IACzB,IAAI,YAAY,cAAc,CAC/B;MAED,IAAM,cAAc,GAAc,EAAE;MACpC,IAAM,aAAa,GAAc,EAAE;MAAC,6CAEhB,IAAI,CAAC,QAAQ;QAAA;MAAA;QAAjC,0DAAmC;UAAA,IAAxB,KAAK;UACd,IAAI,KAAK,YAAY,OAAO,EAAE;YAC5B,IAAI,UAAU,IAAI,CAAC,iBAAiB,CAAC,IAAI,CAAC,cAAc,EAAE,EAAE,KAAK,CAAC,eAAe,EAAE,CAAC,EAAE;cACpF,cAAc,CAAC,IAAI,CAAC,KAAK,CAAC;aAC3B,MAAM;cACL,aAAa,CAAC,IAAI,CAAC,KAAK,CAAC;YAC1B;UACF;;MACF;QAAA;MAAA;QAAA;MAAA;MAED,IAAI,cAAc,CAAC,MAAM,GAAG,CAAC,EAAE;QAC7B,IAAM,WAAW,GAAG,cAAc,CAAC,GAAG,EAAE;QAAC,6CACvB,cAAc;UAAA;QAAA;UAAhC,0DAAkC;YAAA,IAAvB,GAAG;YACZ,WAAW,CAAC,KAAK,CAAC,GAAG,EAAE,IAAI,CAAC,KAAK,CAAC,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;;QACjE;UAAA;QAAA;UAAA;QAAA;QACD,IAAI,CAAC,WAAW,EAAE;QAClB,IAAI,IAAI,YAAY,OAAO,EAAE;UAC3B,IAAI,CAAC,KAAK,CAAC,WAAW,EAAE,IAAI,CAAC,KAAK,CAAC,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;SAClE,MAAM;UACL,WAAW,CAAC,cAAc,EAAE;QAC7B;MACF;MACD,IAAI,aAAa,CAAC,MAAM,GAAG,CAAC,EAAE;QAC5B,IAAM,YAAY,GAAG,aAAa,CAAC,GAAG,EAAE;QAAC,6CACvB,aAAa;UAAA;QAAA;UAA/B,0DAAiC;YAAA,IAAtB,IAAG;YACZ,YAAY,CAAC,KAAK,CAAC,IAAG,EAAE,IAAI,CAAC,KAAK,CAAC,YAAY,CAAC,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC,CAAC;;QAClE;UAAA;QAAA;UAAA;QAAA;QACD,IAAI,CAAC,WAAW,EAAE;MACnB;IACH;EAAC;EAAA;AAAA,EA7C4B,iBAAiB;AAgDhD;;;;;;AAMG;AACH,WAAa,YAAa;EAAA;EAAA;EAAA;IAAA;IAAA;EAAA;EAAA;IAAA;IAAA,OACjB,aAAI,IAAkB,EAAA;MAC3B,IAAM,QAAQ,sBAAO,IAAI,CAAC,QAAQ,CAAC;MACnC,IAAM,cAAc,GAAG,IAAI,CAAC,QAAQ,EAAE,UAAA,KAAK;QAAA,OAAI,KAAK,YAAY,UAAU;MAAA,EAAC;MAE3E,IAAI,CAAC,cAAc,IAAI,IAAI,CAAC,WAAW,EAAE,IAAI,CAAC,EAAE;QAC9C;MACD;MAED,IAAM,aAAa,GAAmB,EAAE;MAExC;MACA;MACA,IAAI,UAAsB;MAAC,6CAEP,QAAQ;QAAA;MAAA;QAA5B,0DAA8B;UAAA,IAAnB,MAAK;UACd,IAAI,MAAK,YAAY,UAAU,EAAE;YAC/B,IAAI,UAAU,GAAG,MAAK;YAEtB,OAAO,UAAU,CAAC,WAAW,EAAE,KAAK,CAAC,EAAE;cACrC,0CAAmB,UAAU,CAAC,QAAQ;gBAA/B,QAAQ;cACf,IAAI,QAAQ,YAAY,UAAU,EAAE;gBAClC,UAAU,GAAG,QAAQ;eACtB,MAAM;gBACL;cACD;YACF;YAED,aAAa,CAAC,IAAI,OAAlB,aAAa,qBAAS,UAAU,CAAC,QAAQ,EAAC;YAE1C,IAAI,UAAU,EAAE;cACd;cACA;cACA;cAEA;cACA,IAAI,CAAC,WAAW,CAAC,MAAK,CAAC;cACvB,MAAK,CAAC,MAAM,GAAG,UAAU,CAAC,MAAM;cAEhC,UAAU,CAAC,MAAM,CAAC,WAAW,CAAC,UAAU,CAAC;cACzC,UAAU,CAAC,MAAM,GAAG,UAAU;cAE9B,IAAI,CAAC,WAAW,EAAE;aACnB,MAAM;cACL,UAAU,GAAG,UAAU;YACxB;WACF,MAAM;YACL,aAAa,CAAC,IAAI,CAAC,MAAK,CAAC;UAC1B;;MACF;QAAA;MAAA;QAAA;MAAA;MAED,IAAI,aAAa,CAAC,MAAM,EAAE;QACxB,IAAI,CAAC,WAAW,EAAE;QAAC,6CACC,aAAa;UAAA;QAAA;UAAjC,0DAAmC;YAAA,IAAxB,KAAK;YACd,KAAK,CAAC,MAAM,CAAC,WAAW,CAAC,KAAK,CAAC;YAC/B,KAAK,CAAC,MAAM,GAAG,UAAU;;QAC1B;UAAA;QAAA;UAAA;QAAA;MACF;IACH;EAAC;EAAA;AAAA,EA1D+B,iBAAiB","sourceRoot":"","sourcesContent":["import { fieldIntersection, hash, hasIntersection, isEmpty, keys, some } from '../../util';\nimport { requiresSelectionId } from '../selection';\nimport { AggregateNode } from './aggregate';\nimport { BinNode } from './bin';\nimport { OutputNode } from './dataflow';\nimport { FacetNode } from './facet';\nimport { FilterNode } from './filter';\nimport { ParseNode } from './formatparse';\nimport { IdentifierNode } from './identifier';\nimport { BottomUpOptimizer, isDataSourceNode, Optimizer, TopDownOptimizer } from './optimizer';\nimport { SourceNode } from './source';\nimport { TimeUnitNode } from './timeunit';\n/**\n * Merge identical nodes at forks by comparing hashes.\n *\n * Does not need to iterate from leaves so we implement this with recursion as it's a bit simpler.\n */\nexport class MergeIdenticalNodes extends TopDownOptimizer {\n    mergeNodes(parent, nodes) {\n        const mergedNode = nodes.shift();\n        for (const node of nodes) {\n            parent.removeChild(node);\n            node.parent = mergedNode;\n            node.remove();\n        }\n    }\n    run(node) {\n        const hashes = node.children.map(x => x.hash());\n        const buckets = {};\n        for (let i = 0; i < hashes.length; i++) {\n            if (buckets[hashes[i]] === undefined) {\n                buckets[hashes[i]] = [node.children[i]];\n            }\n            else {\n                buckets[hashes[i]].push(node.children[i]);\n            }\n        }\n        for (const k of keys(buckets)) {\n            if (buckets[k].length > 1) {\n                this.setModified();\n                this.mergeNodes(node, buckets[k]);\n            }\n        }\n    }\n}\n/**\n * Optimizer that removes identifier nodes that are not needed for selections.\n */\nexport class RemoveUnnecessaryIdentifierNodes extends TopDownOptimizer {\n    constructor(model) {\n        super();\n        this.requiresSelectionId = model && requiresSelectionId(model);\n    }\n    run(node) {\n        if (node instanceof IdentifierNode) {\n            // Only preserve IdentifierNodes if we have default discrete selections\n            // in our model tree, and if the nodes come after tuple producing nodes.\n            if (!(this.requiresSelectionId &&\n                (isDataSourceNode(node.parent) || node.parent instanceof AggregateNode || node.parent instanceof ParseNode))) {\n                this.setModified();\n                node.remove();\n            }\n        }\n    }\n}\n/**\n * Removes duplicate time unit nodes (as determined by the name of the output field) that may be generated due to\n * selections projected over time units. Only keeps the first time unit in any branch.\n *\n * This optimizer is a custom top down optimizer that keep track of produced fields in a branch.\n */\nexport class RemoveDuplicateTimeUnits extends Optimizer {\n    optimize(node) {\n        this.run(node, new Set());\n        return this.modifiedFlag;\n    }\n    run(node, timeUnitFields) {\n        let producedFields = new Set();\n        if (node instanceof TimeUnitNode) {\n            producedFields = node.producedFields();\n            if (hasIntersection(producedFields, timeUnitFields)) {\n                this.setModified();\n                node.removeFormulas(timeUnitFields);\n                if (node.producedFields.length === 0) {\n                    node.remove();\n                }\n            }\n        }\n        for (const child of node.children) {\n            this.run(child, new Set([...timeUnitFields, ...producedFields]));\n        }\n    }\n}\n/**\n * Remove output nodes that are not required.\n */\nexport class RemoveUnnecessaryOutputNodes extends TopDownOptimizer {\n    constructor() {\n        super();\n    }\n    run(node) {\n        if (node instanceof OutputNode && !node.isRequired()) {\n            this.setModified();\n            node.remove();\n        }\n    }\n}\n/**\n * Move parse nodes up to forks and merges them if possible.\n */\nexport class MoveParseUp extends BottomUpOptimizer {\n    run(node) {\n        if (isDataSourceNode(node)) {\n            return;\n        }\n        if (node.numChildren() > 1) {\n            // Don't move parse further up but continue with parent.\n            return;\n        }\n        for (const child of node.children) {\n            if (child instanceof ParseNode) {\n                if (node instanceof ParseNode) {\n                    this.setModified();\n                    node.merge(child);\n                }\n                else {\n                    // Don't swap with nodes that produce something that the parse node depends on (e.g. lookup).\n                    if (fieldIntersection(node.producedFields(), child.dependentFields())) {\n                        continue;\n                    }\n                    this.setModified();\n                    child.swapWithParent();\n                }\n            }\n        }\n        return;\n    }\n}\n/**\n * Inserts an intermediate ParseNode containing all non-conflicting parse fields and removes the empty ParseNodes.\n *\n * We assume that dependent paths that do not have a parse node can be just merged.\n */\nexport class MergeParse extends BottomUpOptimizer {\n    run(node) {\n        const originalChildren = [...node.children];\n        const parseChildren = node.children.filter((child) => child instanceof ParseNode);\n        if (node.numChildren() > 1 && parseChildren.length >= 1) {\n            const commonParse = {};\n            const conflictingParse = new Set();\n            for (const parseNode of parseChildren) {\n                const parse = parseNode.parse;\n                for (const k of keys(parse)) {\n                    if (!(k in commonParse)) {\n                        commonParse[k] = parse[k];\n                    }\n                    else if (commonParse[k] !== parse[k]) {\n                        conflictingParse.add(k);\n                    }\n                }\n            }\n            for (const field of conflictingParse) {\n                delete commonParse[field];\n            }\n            if (!isEmpty(commonParse)) {\n                this.setModified();\n                const mergedParseNode = new ParseNode(node, commonParse);\n                for (const childNode of originalChildren) {\n                    if (childNode instanceof ParseNode) {\n                        for (const key of keys(commonParse)) {\n                            delete childNode.parse[key];\n                        }\n                    }\n                    node.removeChild(childNode);\n                    childNode.parent = mergedParseNode;\n                    // remove empty parse nodes\n                    if (childNode instanceof ParseNode && keys(childNode.parse).length === 0) {\n                        childNode.remove();\n                    }\n                }\n            }\n        }\n    }\n}\n/**\n * Repeatedly remove leaf nodes that are not output or facet nodes.\n * The reason is that we don't need subtrees that don't have any output nodes.\n * Facet nodes are needed for the row or column domains.\n */\nexport class RemoveUnusedSubtrees extends BottomUpOptimizer {\n    run(node) {\n        if (node instanceof OutputNode || node.numChildren() > 0 || node instanceof FacetNode) {\n            // no need to continue with parent because it is output node or will have children (there was a fork)\n        }\n        else if (node instanceof SourceNode) {\n            // ignore empty unused sources as they will be removed in optimizationDataflowHelper\n        }\n        else {\n            this.setModified();\n            node.remove();\n        }\n    }\n}\n/**\n * Merge adjacent time unit nodes.\n */\nexport class MergeTimeUnits extends BottomUpOptimizer {\n    run(node) {\n        const timeUnitChildren = node.children.filter((x) => x instanceof TimeUnitNode);\n        const combination = timeUnitChildren.pop();\n        for (const timeUnit of timeUnitChildren) {\n            this.setModified();\n            combination.merge(timeUnit);\n        }\n    }\n}\nexport class MergeAggregates extends BottomUpOptimizer {\n    run(node) {\n        const aggChildren = node.children.filter((child) => child instanceof AggregateNode);\n        // Object which we'll use to map the fields which an aggregate is grouped by to\n        // the set of aggregates with that grouping. This is useful as only aggregates\n        // with the same group by can be merged\n        const groupedAggregates = {};\n        // Build groupedAggregates\n        for (const agg of aggChildren) {\n            const groupBys = hash(agg.groupBy);\n            if (!(groupBys in groupedAggregates)) {\n                groupedAggregates[groupBys] = [];\n            }\n            groupedAggregates[groupBys].push(agg);\n        }\n        // Merge aggregateNodes with same key in groupedAggregates\n        for (const group of keys(groupedAggregates)) {\n            const mergeableAggs = groupedAggregates[group];\n            if (mergeableAggs.length > 1) {\n                const mergedAggs = mergeableAggs.pop();\n                for (const agg of mergeableAggs) {\n                    if (mergedAggs.merge(agg)) {\n                        node.removeChild(agg);\n                        agg.parent = mergedAggs;\n                        agg.remove();\n                        this.setModified();\n                    }\n                }\n            }\n        }\n    }\n}\n/**\n * Merge bin nodes and move them up through forks. Stop at filters, parse, identifier as we want them to stay before the bin node.\n */\nexport class MergeBins extends BottomUpOptimizer {\n    constructor(model) {\n        super();\n        this.model = model;\n    }\n    run(node) {\n        const moveBinsUp = !(isDataSourceNode(node) ||\n            node instanceof FilterNode ||\n            node instanceof ParseNode ||\n            node instanceof IdentifierNode);\n        const promotableBins = [];\n        const remainingBins = [];\n        for (const child of node.children) {\n            if (child instanceof BinNode) {\n                if (moveBinsUp && !fieldIntersection(node.producedFields(), child.dependentFields())) {\n                    promotableBins.push(child);\n                }\n                else {\n                    remainingBins.push(child);\n                }\n            }\n        }\n        if (promotableBins.length > 0) {\n            const promotedBin = promotableBins.pop();\n            for (const bin of promotableBins) {\n                promotedBin.merge(bin, this.model.renameSignal.bind(this.model));\n            }\n            this.setModified();\n            if (node instanceof BinNode) {\n                node.merge(promotedBin, this.model.renameSignal.bind(this.model));\n            }\n            else {\n                promotedBin.swapWithParent();\n            }\n        }\n        if (remainingBins.length > 1) {\n            const remainingBin = remainingBins.pop();\n            for (const bin of remainingBins) {\n                remainingBin.merge(bin, this.model.renameSignal.bind(this.model));\n            }\n            this.setModified();\n        }\n    }\n}\n/**\n * This optimizer takes output nodes that are at a fork and moves them before the fork.\n *\n * The algorithm iterates over the children and tries to find the last output node in a chain of output nodes.\n * It then moves all output nodes before that main output node. All other children (and the children of the output nodes)\n * are inserted after the main output node.\n */\nexport class MergeOutputs extends BottomUpOptimizer {\n    run(node) {\n        const children = [...node.children];\n        const hasOutputChild = some(children, child => child instanceof OutputNode);\n        if (!hasOutputChild || node.numChildren() <= 1) {\n            return;\n        }\n        const otherChildren = [];\n        // The output node we will connect all other nodes to.\n        // Output nodes will be added before the new node, other nodes after.\n        let mainOutput;\n        for (const child of children) {\n            if (child instanceof OutputNode) {\n                let lastOutput = child;\n                while (lastOutput.numChildren() === 1) {\n                    const [theChild] = lastOutput.children;\n                    if (theChild instanceof OutputNode) {\n                        lastOutput = theChild;\n                    }\n                    else {\n                        break;\n                    }\n                }\n                otherChildren.push(...lastOutput.children);\n                if (mainOutput) {\n                    // Move the output nodes before the mainOutput. We do this by setting\n                    // the parent of the first not to the parent of the main output and\n                    // the main output's parent to the last output.\n                    // note: the child is the first output\n                    node.removeChild(child);\n                    child.parent = mainOutput.parent;\n                    mainOutput.parent.removeChild(mainOutput);\n                    mainOutput.parent = lastOutput;\n                    this.setModified();\n                }\n                else {\n                    mainOutput = lastOutput;\n                }\n            }\n            else {\n                otherChildren.push(child);\n            }\n        }\n        if (otherChildren.length) {\n            this.setModified();\n            for (const child of otherChildren) {\n                child.parent.removeChild(child);\n                child.parent = mainOutput;\n            }\n        }\n    }\n}\n//# sourceMappingURL=optimizers.js.map"]},"metadata":{},"sourceType":"module"}